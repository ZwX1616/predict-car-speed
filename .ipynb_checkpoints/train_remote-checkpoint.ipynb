{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable as V\n",
    "import torch as th\n",
    "from torchvision import models\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "from alexlstm import AlexLSTM\n",
    "from datasetutil import DatasetUtil\n",
    "from importlib import reload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "batch_size = 5\n",
    "time_stamp = 20\n",
    "frame_offset_per_time_stamp = 10\n",
    "train_dataset = os.listdir(\"img/\")\n",
    "total_img_num = len(train_dataset)\n",
    "iteration_per_epoch = int(total_img_num / (batch_size*time_stamp))\n",
    "\n",
    "def train():\n",
    "    net = AlexLSTM().cuda()\n",
    "    util = DatasetUtil()\n",
    "    criterion = nn.MSELoss(False)\n",
    "    lr = 0.0001\n",
    "    min_loss = 100\n",
    "    for epoch in range(20):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i in range(iteration_per_epoch):\n",
    "            x,y = util.fetch_image_and_label(batch_size, time_stamp, frame_offset_per_time_stamp, total_img_num)\n",
    "            \n",
    "            # wrap them in Variable\n",
    "            x = V(th.from_numpy(x).float()).cuda()\n",
    "            y = V(th.from_numpy(y).float()).cuda()\n",
    "\n",
    "            optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "            optimizer.zero_grad()# zero the parameter gradients\n",
    "            # forward + backward + optimize\n",
    "            predict = net(x)\n",
    "\n",
    "            print(\"------------ PREDICT ------------\")\n",
    "            print(predict)\n",
    "            print(\"------------ LABEL --------------\")\n",
    "            print(y)\n",
    "            loss = criterion(predict, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.data[0]\n",
    "            if running_loss <= min_loss :\n",
    "                min_loss = running_loss\n",
    "                print(\"--- Found smaller loss ---\")\n",
    "                th.save(net.state_dict(), 'weight/%d_%s.p' % (i, epoch))\n",
    "            print('[epoch : %d, iteration : %5d] loss: %.3f' % (epoch, i, running_loss))\n",
    "            running_loss = 0.0\n",
    "        print(\"Saving model per epoch...\")\n",
    "        th.save(net.state_dict(), 'weight/epoch_%s.p' % (epoch))\n",
    "    print('Finished Training')\n",
    "\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
