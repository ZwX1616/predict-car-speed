{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15459 2.232426\n",
      "15460 2.128592\n",
      "15461 2.037299\n",
      "15462 2.062311\n",
      "15463 1.986056\n",
      "15464 1.879097\n",
      "15465 1.91522\n",
      "15466 1.817642\n",
      "15467 1.729141\n",
      "15468 1.753493\n",
      "15469 1.668238\n",
      "15470 1.638134\n",
      "15471 1.634793\n",
      "15472 1.533554\n",
      "15473 1.51216\n",
      "15474 1.500449\n",
      "15475 1.452962\n",
      "15476 1.448734\n",
      "15477 1.421214\n",
      "15478 1.329434\n",
      "2968 22.17625\n",
      "2969 22.133444\n",
      "2970 22.149298\n",
      "2971 22.100728\n",
      "2972 22.060368\n",
      "2973 21.988514\n",
      "2974 21.975832\n",
      "2975 21.958813\n",
      "2976 21.906158\n",
      "2977 21.90997\n",
      "2978 21.863792\n",
      "2979 21.854736\n",
      "2980 21.83847\n",
      "2981 21.78667\n",
      "2982 21.804916\n",
      "2983 21.792359\n",
      "2984 21.774163\n",
      "2985 21.761638\n",
      "2986 21.775377\n",
      "2987 21.753186\n",
      "8837 10.205999\n",
      "8838 10.182577\n",
      "8839 10.158643\n",
      "8840 10.182892\n",
      "8841 10.127035\n",
      "8842 10.115971\n",
      "8843 10.113069\n",
      "8844 10.082145\n",
      "8845 10.039093\n",
      "8846 10.041261\n",
      "8847 10.026185\n",
      "8848 9.975841\n",
      "8849 9.951443\n",
      "8850 9.945091\n",
      "8851 9.940427\n",
      "8852 9.886067\n",
      "8853 9.888366\n",
      "8854 9.881791\n",
      "8855 9.856683\n",
      "8856 9.843443\n",
      "12782 9.374195\n",
      "12783 9.299342\n",
      "12784 9.301712\n",
      "12785 9.17977\n",
      "12786 9.229411\n",
      "12787 9.136078\n",
      "12788 9.112845\n",
      "12789 9.13455\n",
      "12790 9.063305\n",
      "12791 9.066781\n",
      "12792 9.052585\n",
      "12793 9.046257\n",
      "12794 9.039394\n",
      "12795 9.025224\n",
      "12796 8.90991\n",
      "12797 8.835087\n",
      "12798 8.793431\n",
      "12799 8.8036\n",
      "12800 8.808343\n",
      "12801 8.777193\n",
      "17069 1.714856\n",
      "17070 1.734268\n",
      "17071 1.773591\n",
      "17072 1.889902\n",
      "17073 1.883502\n",
      "17074 1.993563\n",
      "17075 2.109367\n",
      "17076 2.066758\n",
      "17077 2.213218\n",
      "17078 2.32716\n",
      "17079 2.50344\n",
      "17080 2.466929\n",
      "17081 2.58477\n",
      "17082 2.720589\n",
      "17083 2.670654\n",
      "17084 2.877819\n",
      "17085 2.974744\n",
      "17086 2.9482\n",
      "17087 3.056305\n",
      "17088 3.087244\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[42]:\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable as V\n",
    "import torch as th\n",
    "from torchvision import models\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "\n",
    "class AlexLSTM(nn.Module):\n",
    "    def __init__(self, n_layers=2, h_size=420):\n",
    "        super(AlexLSTM, self).__init__()\n",
    "        self.h_size = h_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        alexnet = models.alexnet(pretrained=True)\n",
    "        self.conv = nn.Sequential(*list(alexnet.children())[:-1])\n",
    "\n",
    "        self.lstm = nn.LSTM(68096, h_size, dropout=0.2, num_layers=n_layers)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(h_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (batch_size, 3, time_stamp, 480, 640)\n",
    "        batch_size, timesteps = x.size()[0], x.size()[2]\n",
    "        state = self._init_state(b_size=batch_size)\n",
    "\n",
    "        convs = []\n",
    "        for t in range(timesteps):\n",
    "            conv = self.conv(x[:, :, t, :, :])\n",
    "#             print(\"conv shape : \", conv.size())\n",
    "            conv = conv.view(batch_size, -1)\n",
    "#             print(\"conv reshape :\", conv.size())\n",
    "            convs.append(conv)\n",
    "        convs = th.stack(convs, 0)\n",
    "        print(\"alex output shape : \",convs.size()) # ([20, 5, 68096]) (seq_len, batch, input_size)\n",
    "        print(\"lstm input shape : \",convs.size())\n",
    "        lstm, _ = self.lstm(convs, state) # lstm input (seq_len, batch, input_size)\n",
    "        print(\"lstm output shape : \",lstm.size()) # torch.Size([20, 5, 420]) (seq_len, batch, hidden_size * num_directions)\n",
    "        print(\"fc input shape : \",lstm.size())\n",
    "        logit = self.fc(lstm) # seq_len, batch, input_size ([20, 5, 1])\n",
    "        print(\"fc output shape : \",logit.size())\n",
    "        \n",
    "        logit = logit.transpose(1,0).squeeze(2)\n",
    "        return logit\n",
    "\n",
    "    def _init_state(self, b_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return (\n",
    "            V(weight.new(self.n_layers, b_size, self.h_size).normal_(0.0, 0.01)),\n",
    "            V(weight.new(self.n_layers, b_size, self.h_size).normal_(0.0, 0.01))\n",
    "        )\n",
    "    \n",
    "batch_size = 5\n",
    "time_stamp = 20\n",
    "train_dataset = os.listdir(\"../img/\")\n",
    "total_img_num = len(train_dataset)\n",
    "iteration_per_epoch = int(total_img_num / (batch_size*time_stamp))\n",
    "\n",
    "def fetch_image_and_label(batch_size, time_stamp):\n",
    "    numbers = []\n",
    "    while(len(numbers) != batch_size):\n",
    "        a = random.randint(0,total_img_num-time_stamp)\n",
    "        if a not in numbers:\n",
    "            numbers.append(a)\n",
    "    label = []\n",
    "    file_in = open('../data/train.txt', 'r')\n",
    "    for line in file_in.readlines():\n",
    "        label.append(float(line))\n",
    "    \n",
    "    x = np.zeros((batch_size, time_stamp, 480, 640, 3))\n",
    "    y = np.zeros((batch_size, time_stamp))\n",
    "    for i in range(batch_size):\n",
    "        for j in range(time_stamp):\n",
    "            img_name = numbers[i] + j\n",
    "            image_path = '../img/frame' + str(img_name) + \".jpg\"\n",
    "            img = cv2.imread(image_path)\n",
    "            x[i,j] = img\n",
    "            y[i,j] = label[numbers[i] + j]\n",
    "            \n",
    "            print(img_name, y[i,j])\n",
    "    x = x.transpose(0, 4, 1, 2, 3) # (batch_size, 3, time_stamp, 480, 640)\n",
    "    return x, y\n",
    "\n",
    "def train():\n",
    "    net = AlexLSTM()\n",
    "    criterion = nn.MSELoss(False)\n",
    "    lr = 0.0001\n",
    "    min_loss = 100\n",
    "    for epoch in range(20):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i in range(iteration_per_epoch):\n",
    "            x,y = fetch_image_and_label(batch_size, time_stamp)\n",
    "\n",
    "            # wrap them in Variable\n",
    "            x = V(th.from_numpy(x).float())\n",
    "            y = V(th.from_numpy(y).float())\n",
    "\n",
    "            optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "            optimizer.zero_grad()# zero the parameter gradients\n",
    "            # forward + backward + optimize\n",
    "            predict = net(x)\n",
    "\n",
    "            print(\"predict shape : \", predict.size())\n",
    "            print(\"label shape : \", y.size())\n",
    "            print(\"------ PREDICT start------\")\n",
    "            print(predict)\n",
    "            print(\"------ PREDICT   end------\")\n",
    "            print(\"------ LABEL start------\")\n",
    "            print(y)\n",
    "            print(\"------ LABEL   end------\")\n",
    "            loss = criterion(predict, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            print(\"loss shape : \",loss.data.size())\n",
    "            running_loss += loss.data[0]\n",
    "            if running_loss <= min_loss :\n",
    "                min_loss = running_loss\n",
    "                print(\"Saving model ...\")\n",
    "                th.save(net.state_dict(), '../weight/%d_%s.p' % (i, epoch))\n",
    "            print('[epoch : %d, iteration : %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        print(\"Saving model ...\")\n",
    "        th.save(net.state_dict(), '../weight/epoch_%s.p' % (epoch))\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "#     train()\n",
    "    fetch_image_and_label(batch_size, time_stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
