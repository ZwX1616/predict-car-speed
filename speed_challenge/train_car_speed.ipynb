{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable as V\n",
    "import torch as th\n",
    "from torchvision import models\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "\n",
    "class AlexLSTM(nn.Module):\n",
    "    def __init__(self, n_layers=2, h_size=420):\n",
    "        super(AlexLSTM, self).__init__()\n",
    "        self.h_size = h_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        alexnet = models.alexnet(pretrained=True)\n",
    "        self.conv = nn.Sequential(*list(alexnet.children())[:-1])\n",
    "\n",
    "        self.lstm = nn.LSTM(68096, h_size, dropout=0.2, num_layers=n_layers)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(h_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (batch_size, 3, time_stamp, 480, 640)\n",
    "        batch_size, timesteps = x.size()[0], x.size()[2]\n",
    "        state = self._init_state(b_size=batch_size)\n",
    "\n",
    "        convs = []\n",
    "        for t in range(timesteps):\n",
    "            conv = self.conv(x[:, :, t, :, :])\n",
    "#             print(\"conv shape : \", conv.size())\n",
    "            conv = conv.view(batch_size, -1)\n",
    "#             print(\"conv reshape :\", conv.size())\n",
    "            convs.append(conv)\n",
    "        convs = th.stack(convs, 0)\n",
    "        print(\"alex output shape : \",convs.size()) # ([20, 5, 68096]) (seq_len, batch, input_size)\n",
    "        print(\"lstm input shape : \",convs.size())\n",
    "        lstm, _ = self.lstm(convs, state) # lstm input (seq_len, batch, input_size)\n",
    "        print(\"lstm output shape : \",lstm.size()) # torch.Size([20, 5, 420]) (seq_len, batch, hidden_size * num_directions)\n",
    "        print(\"fc input shape : \",lstm.size())\n",
    "        logit = self.fc(lstm) # seq_len, batch, input_size ([20, 5, 1])\n",
    "        print(\"fc output shape : \",logit.size())\n",
    "        \n",
    "        logit = logit.transpose(1,0).squeeze(2)\n",
    "        return logit\n",
    "\n",
    "    def _init_state(self, b_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return (\n",
    "            V(weight.new(self.n_layers, b_size, self.h_size).normal_(0.0, 0.01)),\n",
    "            V(weight.new(self.n_layers, b_size, self.h_size).normal_(0.0, 0.01))\n",
    "        )\n",
    "    \n",
    "net = AlexLSTM()\n",
    "net = net.cuda()\n",
    "# print(net)\n",
    "\n",
    "batch_size = 1 #5\n",
    "time_stamp = 40  #20\n",
    "train_dataset = os.listdir(\"../img/\")\n",
    "total_img_num = len(train_dataset)\n",
    "iteration_per_epoch = int(total_img_num / (batch_size*time_stamp))\n",
    "lr = 0.001 # 0.0001\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def fetch_image_and_label(batch_size, time_stamp):\n",
    "    numbers = []\n",
    "    while(len(numbers) != batch_size):\n",
    "        a = random.randint(0,total_img_num-time_stamp)\n",
    "        if a not in numbers:\n",
    "            numbers.append(a)\n",
    "    label = []\n",
    "    file_in = open('../data/train.txt', 'r')\n",
    "    for line in file_in.readlines():\n",
    "        label.append(float(line))\n",
    "    \n",
    "    x = np.zeros((batch_size, time_stamp, 480, 640, 3))\n",
    "    y = np.zeros((batch_size, time_stamp))\n",
    "    for i in range(batch_size):\n",
    "        for j in range(time_stamp):\n",
    "            img_name = numbers[i] + j\n",
    "            image_path = '../img/frame' + str(img_name) + \".jpg\"\n",
    "            img = cv2.imread(image_path)\n",
    "            x[i,j] = img\n",
    "            y[i,j] = label[numbers[i] + j]\n",
    "    \n",
    "    x = x.transpose(0, 4, 1, 2, 3) # (batch_size, 3, time_stamp, 480, 640)\n",
    "    return x, y\n",
    "    \n",
    "min_loss = 100\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i in range(iteration_per_epoch):\n",
    "        x,y = fetch_image_and_label(batch_size, time_stamp)\n",
    "\n",
    "        # wrap them in Variable\n",
    "        x = V(th.from_numpy(x).float()).cuda()\n",
    "        y = V(th.from_numpy(y).float()).cuda()\n",
    "\n",
    "        optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "        optimizer.zero_grad()# zero the parameter gradients\n",
    "        # forward + backward + optimize\n",
    "        predict = net(x)\n",
    "        \n",
    "        print(\"predict shape : \", predict.size())\n",
    "        print(\"label shape : \", y.size())\n",
    "        print(\"------ PREDICT start------\")\n",
    "        print(predict)\n",
    "        print(\"------ PREDICT   end------\")\n",
    "        print(\"------ LABEL start------\")\n",
    "        print(y)\n",
    "        print(\"------ LABEL   end------\")\n",
    "        loss = criterion(predict, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        print(\"loss shape : \",loss.size())\n",
    "        print(\"loss.data shape : \",loss.data.size())\n",
    "        running_loss += loss.data[0]\n",
    "        if running_loss <= min_loss :\n",
    "            min_loss = running_loss\n",
    "            print(\"Found new min_loss !!!!!!!!! : \" , min_loss)\n",
    "            print(\"Saving model ...\")\n",
    "            th.save(net.state_dict(), '../weight/%d_%s.p' % (i, epoch))\n",
    "        print('[epoch : %d, iteration : %d] loss: %.3f' % (epoch, i, running_loss))\n",
    "        running_loss = 0.0\n",
    "    print(\"Saving model ...\")\n",
    "    th.save(net.state_dict(), '../weight/epoch_%s.p' % (epoch))\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
